"""Service for chat interactions with Ollama."""

import logging
import re
from typing import List, Dict, Optional, Tuple, Any

import ollama
import os

from app.config import settings

# Configure Ollama client URL if specified
# Ollama uses OLLAMA_HOST environment variable (format: host:port)
if settings.ollama_url:
    # Extract host:port from URL (e.g., http://localhost:11434 -> localhost:11434)
    url_parts = settings.ollama_url.replace("http://", "").replace("https://", "")
    os.environ["OLLAMA_HOST"] = url_parts
from app.exceptions import OllamaError
from app.models.schemas import ChatRequest, MessageHistory
from app.services.news_service import NewsService
from app.services.campus_service import CampusService
from app.services.degrees_service import DegreesService
from app.services.pedagogy_service import PedagogyService
from app.services.geocoding_service import GeocodingService
from app.utils.campus_data import CAMPUSES, CITY_ALIASES, format_campus_list
from app.utils.language_detection import detect_language
from app.utils.tool_router import ToolRouter
from app.utils.tool_router import ToolDecision
from app.utils.epitech_faq import methodology_fr, methodology_en

logger = logging.getLogger(__name__)


class ChatService:
    """Service for handling chat interactions."""

    def __init__(self):
        """Initialize chat service with dependencies."""
        self.news_service = NewsService()
        self.campus_service = CampusService()
        self.degrees_service = DegreesService()
        self.pedagogy_service = PedagogyService()
        self.geocoding_service = GeocodingService()

    # Keywords for intent detection
    NEWS_KEYWORDS = ["news", "actualit√©", "actu", "nouveaut√©", "√©v√©nement"]

    DEGREES_KEYWORDS = [
        "diplome", "dipl√¥me", "diplomes", "dipl√¥mes",
        "programme", "programmes", "cursus", "formation", "formations",
        "msc", "master", "master of science", "bachelor",
        "coding academy", "web@cad√©mie", "web@academie",
    ]
    
    NON_LOCATION_KEYWORDS = [
        "m√©thodologie", "methodologie", "p√©dagogie", "pedagogie", "programme",
        "cursus", "formation", "apprentissage", "m√©thode", "enseignement",
        "√©tude", "cours", "diplome", "dipl√¥me",
        "int√©ressant", "interessant", "cool", "sympa", "super", "g√©nial",
        "l'air", "lair", "semble", "parait", "para√Æt"
    ]
    
    INVALID_LOCATION_WORDS = {
        "l", "la", "le", "les", "un", "une", "des", "air", "lair", "l'air",
        "bien", "mal", "bon", "bonne", "tr√®s", "trop", "peu", "plus",
        "√™tre", "etre", "avoir", "fait", "faire", "dit", "dire",
        "int√©ressant", "interessant", "cool", "sympa", "super"
    }

    # STOP-WORDS / SUJETS INTERDITS
    # Si ces mots sont d√©tect√©s sans contexte Epitech fort, on coupe court.
    FORBIDDEN_KEYWORDS = [
        "recette", "cuisine", "g√¢teau", "tarte", "pizza", "cuire", "manger",
        "m√©t√©o", "climat", "pluie", "soleil", "temp√©rature",
        "politique", "pr√©sident", "ministre", "√©lection", "vote", "loi",
        "sport", "football", "match", "joueur", "√©quipe",
        "cin√©ma", "film", "acteur", "s√©rie", "netflix",
        "musique", "chanson", "album", "artiste",
        "histoire", "napol√©on", "guerre", "roi", "reine", "date de",
        "math", "physique", "chimie", "√©quation", "calcul", "racine carr√©e",
        "m√©decine", "docteur", "maladie", "sympt√¥me", "traitement",
        "blague", "raconte", "po√®me", "poesie", "histoire dr√¥le"
    ]
    
    LEVEL_KEYWORDS = {
        "bac": [
            "bac ", "bac+0", "baccalaur√©at", "terminale", "stmg", "sti2d",
            "stl", "st2s", "bac s", "bac es", "bac l",
            "bac pro", "bac techno"
        ],
        "bac+2": ["bac+2", "bts", "dut", "deug", "l2", "licence 2"],
        "bac+3": ["bac+3", "licence", "bachelor", "l3", "licence 3"],
        "bac+4": ["bac+4", "m1", "master 1", "ma√Ætrise"],
        "bac+5": ["bac+5", "m2", "master 2", "ing√©nieur", "dipl√¥me d'ing√©nieur"],
        "reconversion": [
            "reconversion", "changement de carri√®re", "r√©orientation",
            "salari√©", "demandeur d'emploi"
        ],
        "lycee": ["lyc√©e", "lyceen", "seconde", "premi√®re", "1√®re", "2nde"]
    }

    async def process_chat(self, request: ChatRequest) -> Dict[str, str]:
        """
        Process a chat request and return AI response.
        
        Args:
            request: Chat request with message and history
        
        Returns:
            Dictionary with response and backend_source
        
        Raises:
            OllamaError: If Ollama API fails
        """
        print("=" * 60)
        print(f"üì® NOUVELLE REQU√äTE RE√áUE")
        print(f"   Message: {request.message[:100]}{'...' if len(request.message) > 100 else ''}")
        print(f"   Historique: {len(request.history)} messages")
        print("=" * 60)
        
        try:
            # Detect language
            print("üîç [1/6] D√©tection de la langue...")
            user_lang = detect_language(
                request.message,
                min_words=settings.min_words_for_lang_detection
            )
            if user_lang != "fr":
                logger.info(f"Language detected: {user_lang}")
                print(f"   ‚úì Langue d√©tect√©e: {user_lang}")
            else:
                print(f"   ‚úì Langue par d√©faut: fran√ßais")

            # Build context from tools
            context_extra = ""
            backend_source = f"Ollama Local ({settings.ollama_model})"
            msg_lower = request.message.lower()

            # -------------------------------------------------------------------------
            # 0. GARDE-FOU IMM√âDIAT (FORBIDDEN TOPICS)
            # -------------------------------------------------------------------------
            # On v√©rifie si l'utilisateur parle de sujets interdits AVANT M√äME de lancer l'IA.
            # Exception : si le mot "site" est pr√©sent (pour "site web"), on laisse passer "site" n'est pas interdit mais bon.
            # On v√©rifie si un mot interdit est pr√©sent. Si "tech" ou "code" ou "web" est aussi pr√©sent, on peut √™tre plus cl√©ment,
            # mais dans le doute, on bloque les recettes etc.
            is_forbidden = any(bad in msg_lower for bad in self.FORBIDDEN_KEYWORDS)
            
            # Sauf si c'est une "blague de dev" demand√©e explicitement dans un contexte tech
            # (mais pour l'instant on bloque tout pour √™tre s√ªr).
            
            if is_forbidden:
                 print(f"   ‚õî SUJET INTERDIT D√âTECT√â (Mot-cl√© trouv√© dans le message)")
                 if user_lang != "fr":
                    return {
                        "response": "I am EpiQuoi, an expert on Epitech orientation. I cannot answer questions about other topics (cooking, weather, politics, general knowledge...). Do you have a question about the school?",
                        "backend_source": "Guardrail (Forbidden Topic)",
                    }
                 return {
                    "response": "Je suis **EpiQuoi**, expert en orientation Epitech. Je ne peux pas r√©pondre aux questions sur d'autres sujets (cuisine, m√©t√©o, politique, culture g√©n√©rale...). As-tu une question sur l'√©cole ?",
                    "backend_source": "Guardrail (Sujet Interdit)",
                }

            # -------------------------------------------------------------------------

            # Conversation-aware context: user may omit "Epitech" in a follow-up.
            def _has_epitech_context() -> bool:
                if "epitech" in msg_lower:
                    return True
                # Look at a few recent turns for "epitech" (user or assistant)
                # REDUCTION DE LA FENETRE DE CONTEXTE A 3 MESSAGES (vs 6 avant)
                # pour √©viter les "fuites" de contexte trop lointaines.
                for turn in reversed(request.history[-3:]):
                    if "epitech" in (turn.text or "").lower():
                        return True
                return False

            def _degrees_followup_context() -> bool:
                """
                Detect a follow-up like:
                  user: "quelles formations ?"
                  bot: "Tu parles des formations d'Epitech ? ... niveau + ville"
                  user: "bac+3"
                In that case, we SHOULD call the degrees tool even if the current message has no keywords.
                """
                # Current message is likely just a level/short confirmation
                short = len(msg_lower.strip()) <= 20
                looks_like_level = any(
                    k in msg_lower
                    for k in (
                        "bac+",
                        "bac +",
                        "bts",
                        "dut",
                        "licence",
                        "master",
                        "reconversion",
                        "lyc√©e",
                        "lycee",
                    )
                )
                if not (short and looks_like_level):
                    return False

                # Recent assistant prompt asking about Epitech formations/programmes/specialisations
                for turn in reversed(request.history[-4:]):
                    if turn.sender == "bot":
                        t = (turn.text or "").lower()
                        if (
                            ("formations" in t or "programme" in t or "dipl" in t or "sp√©cialisation" in t or "specialisation" in t)
                            and ("epitech" in t)
                            and (("bachelor" in t) or ("msc" in t) or ("master of science" in t) or ("pr√©-msc" in t) or ("pre-msc" in t))
                        ):
                            return True
                return False

            epitech_context = _has_epitech_context()
            degrees_followup = _degrees_followup_context()

            # Off-topic guard must be based on the CURRENT message, even if the conversation previously mentioned Epitech.
            # Otherwise the model will answer anything (Minecraft, etc.) just because earlier turns were about Epitech.
            epitech_related_hints_current = (
                ("epitech" in msg_lower)
                or ("campus" in msg_lower)
                or ("√©cole" in msg_lower) or ("ecole" in msg_lower)
                or ("formation" in msg_lower)
                or ("formations" in msg_lower)
                or ("programme" in msg_lower)
                or ("programmes" in msg_lower)
                or ("dipl" in msg_lower)
                or ("specialisation" in msg_lower)
                or ("sp√©cialisation" in msg_lower)
                or ("specialisations" in msg_lower)
                or ("sp√©cialisations" in msg_lower)
                or ("msc" in msg_lower)
                or ("bachelor" in msg_lower)
                or ("mba" in msg_lower)
                or ("coding academy" in msg_lower)
                or ("web@cad" in msg_lower)
                or ("admission" in msg_lower)
                or ("inscription" in msg_lower)
                or ("p√©dagogie" in msg_lower)
                or ("pedagogie" in msg_lower)
                or ("m√©thodologie" in msg_lower)
                or ("methodologie" in msg_lower)
                or ("code" in msg_lower) or ("codage" in msg_lower) or ("d√©veloppeur" in msg_lower)
                or ("informatique" in msg_lower)
            )

            # Allow tiny follow-ups that rely on previous context (level confirmations, yes/no, city).
            msg_stripped = msg_lower.strip()
            is_short_followup = (
                len(msg_stripped) <= 24
                and (
                    degrees_followup
                    or msg_stripped in {"oui", "non", "ok", "daccord", "d'accord", "merci", "yes", "no", "salut", "bonjour", "hello", "hi"}
                    or re.search(r"\bbac\s*\+\s*\d\b", msg_stripped) is not None
                    or any(city.lower() == msg_stripped for city in CAMPUSES.keys())
                )
            )

            # Si on a un contexte Epitech (historique r√©cent) MAIS que le message actuel ne contient
            # AUCUN mot cl√© li√© √† l'√©cole/informatique ET n'est pas un court follow-up :
            # C'est probablement une digression (ex: "Et les pommes ?").
            # On force le guardrail ici.
            if not epitech_related_hints_current and not is_short_followup and not epitech_context:
                print("   ‚õî HORS SUJET D√âTECT√â (Pas de mots-cl√©s Epitech ni contexte)")
                if user_lang != "fr":
                    return {
                        "response": "I‚Äôm EpiQuoi ‚Äî I only handle Epitech questions (campuses, programs, admissions). What would you like to know about Epitech?",
                        "backend_source": "Off-topic",
                    }
                return {
                    "response": "Je suis **EpiQuoi** : je r√©ponds uniquement aux questions li√©es √† **Epitech** (campus, formations, admissions). Tu veux savoir quoi sur Epitech ?",
                    "backend_source": "Off-topic",
                }

            # If it's a methodology/pedagogy question, prefer the official page via MCP tool.
            # If the tool fails, fallback to the trusted FAQ snippet.
            if epitech_context and any(k in msg_lower for k in ("m√©thodologie", "methodologie", "p√©dagogie", "pedagogie", "p√©dago", "pedago")):
                tool_decisions = ToolRouter.route(request.message, epitech_context=epitech_context)
                if tool_decisions.get("pedagogy") and tool_decisions["pedagogy"].call:
                    pedagogy_data = await self.pedagogy_service.get_pedagogy_info()
                    if pedagogy_data and isinstance(pedagogy_data, dict):
                        p = pedagogy_data.get("data", {}) if isinstance(pedagogy_data.get("data"), dict) else {}
                        pillars = p.get("pillars") or []
                        pillars_txt = ", ".join(pillars) if isinstance(pillars, list) and pillars else None
                        url = p.get("url")
                        if user_lang != "fr":
                            return {
                                "response": (
                                    "Epitech‚Äôs pedagogy is mainly **project-based learning** (active learning).\n"
                                    f"- **Core pillars**: {pillars_txt or 'practice, collaboration, teamwork, communication'}\n"
                                    "- **Goal**: learn by building, reasoning, and solving problems.\n\n"
                                    f"Official page: {url}" if url else ""
                                ).strip(),
                                "backend_source": "MCP Tool (pedagogy)",
                            }
                        return {
                            "response": (
                                "La p√©dagogie Epitech est surtout une **p√©dagogie par projets** (p√©dagogie active).\n"
                                f"- **Piliers** : {pillars_txt or 'la pratique, la collaboration, l‚Äôesprit d‚Äô√©quipe, la communication'}\n"
                                "- **Objectif** : apprendre en construisant, raisonner, acqu√©rir une m√©thode de r√©solution de probl√®mes.\n\n"
                                f"Source officielle : {url}" if url else ""
                            ).strip(),
                            "backend_source": "MCP Tool (p√©dagogie)",
                        }

                # Fallback
                if user_lang != "fr":
                    return {"response": methodology_en(), "backend_source": "FAQ (methodology)"}
                return {"response": methodology_fr(), "backend_source": "FAQ (m√©thodologie)"}

            # If user asks about programs/specializations without saying "Epitech",
            # we still prefer scraping (to avoid hallucinations) and we ask 1 short clarification in the final answer.
            needs_track_clarification = False
            if (
                ("formation" in msg_lower)
                or ("formations" in msg_lower)
                or ("programme" in msg_lower)
                or ("dipl" in msg_lower)
                or ("specialisation" in msg_lower)
                or ("sp√©cialisation" in msg_lower)
                or ("specialisations" in msg_lower)
                or ("sp√©cialisations" in msg_lower)
            ) and not epitech_context:
                needs_track_clarification = True

            tool_decisions = ToolRouter.route(request.message, epitech_context=epitech_context)
            if degrees_followup and not tool_decisions["degrees"].call:
                tool_decisions["degrees"] = ToolDecision(
                    call=True,
                    score=tool_decisions["degrees"].score,
                    reasons=tool_decisions["degrees"].reasons + ["forced follow-up (level answer after formations question)"],
                )

            # If it's clearly Epitech-related but router is unsure, do a light speculative scrape in parallel
            # (campus + degrees) to avoid hallucinations.
            if epitech_context and not any(d.call for d in tool_decisions.values()):
                if any(k in msg_lower for k in ("campus", "ville", "adresse", "formation", "formations", "programme", "dipl")):
                    tool_decisions["campus"] = ToolDecision(
                        call=True,
                        score=tool_decisions["campus"].score,
                        reasons=tool_decisions["campus"].reasons + ["speculative scrape (ambiguous epitech question)"],
                    )
                    tool_decisions["degrees"] = ToolDecision(
                        call=True,
                        score=tool_decisions["degrees"].score,
                        reasons=tool_decisions["degrees"].reasons + ["speculative scrape (ambiguous epitech question)"],
                    )
            print(
                "üß∞ [ROUTER] D√©cisions tools: "
                f"news(call={tool_decisions['news'].call}, score={tool_decisions['news'].score:.1f}) | "
                f"campus(call={tool_decisions['campus'].call}, score={tool_decisions['campus'].score:.1f}) | "
                f"degrees(call={tool_decisions['degrees'].call}, score={tool_decisions['degrees'].score:.1f}) | "
                f"pedagogy(call={tool_decisions.get('pedagogy').call if tool_decisions.get('pedagogy') else False}, "
                f"score={tool_decisions.get('pedagogy').score if tool_decisions.get('pedagogy') else 0.0:.1f})"
            )

            # Run selected tools in parallel (faster when multiple tools are needed).
            import asyncio

            tool_tasks: Dict[str, asyncio.Task] = {}
            if tool_decisions["news"].call:
                tool_tasks["news"] = asyncio.create_task(self.news_service.get_epitech_news())
            if tool_decisions["campus"].call:
                tool_tasks["campus"] = asyncio.create_task(self.campus_service.get_campus_info())
            if tool_decisions["degrees"].call:
                tool_tasks["degrees"] = asyncio.create_task(self.degrees_service.get_degrees_info())
            if tool_decisions.get("pedagogy") and tool_decisions["pedagogy"].call:
                tool_tasks["pedagogy"] = asyncio.create_task(self.pedagogy_service.get_pedagogy_info())

            # Tool 1: News Scraper
            print("üîç [2/6] V√©rification si scraper NEWS n√©cessaire...")
            if tool_decisions["news"].call:
                print("   ‚ö° SCRAPER NEWS ACTIV√â - D√©marrage...")
                if tool_decisions["news"].reasons:
                    print(f"   ‚Ü≥ raisons: {', '.join(tool_decisions['news'].reasons[:6])}")
                logger.info("Tool Activation: Scraper Epitech News")
                news_info = await tool_tasks["news"]
                print("   ‚úì Scraping news termin√© avec succ√®s")
                context_extra += (
                    f"\n\n[SYST√àME: DONN√âES LIVE INJECT√âES]\n"
                    f"{news_info}\nUtilise ces informations pour r√©pondre."
                )
                backend_source += " + Scraper News"
            else:
                print("   ‚Üí Pas de scraper news n√©cessaire")

            # Tool 1.5: Campus Scraper (Live)
            print("üîç [2.5/6] V√©rification demande scraping campus...")
            if tool_decisions["campus"].call:
                print("   ‚ö° SCRAPER CAMPUS ACTIV√â - D√©marrage...")
                if tool_decisions["campus"].reasons:
                    print(f"   ‚Ü≥ raisons: {', '.join(tool_decisions['campus'].reasons[:6])}")
                logger.info("Tool Activation: Scraper Campus")
                campus_data = await tool_tasks["campus"]
                
                if campus_data:
                    # MCP returns {"data": [...], "meta": {...}}
                    if isinstance(campus_data, dict) and isinstance(campus_data.get("data"), list):
                        print(
                            "   ‚úì Scraping campus termin√© : "
                            f"{len(campus_data.get('data', []))} campus d√©tect√©s (via MCP.data)"
                        )
                    elif isinstance(campus_data, list):
                        print(f"   ‚úì Scraping campus termin√© : {len(campus_data)} campus d√©tect√©s (list brute)")
                    else:
                        print(
                            f"   ‚ö†Ô∏è Format de donn√©es inattendu : {type(campus_data)} "
                            "(attendu: dict{data} ou list)"
                        )
                    
                    # Optimize data to prevent context overflow (OOM)
                    optimized_data = self._optimize_campus_data(campus_data)
                    print(f"   ‚úì Donn√©es optimis√©es : {len(optimized_data)} campus conserv√©s apr√®s filtrage")
                    
                    # Convert to text to save tokens (JSON is too heavy)
                    campus_text = self._format_campus_to_text(optimized_data)
                    print(f"   ‚úì Texte g√©n√©r√© pour le prompt (DEBUG) :\n{campus_text}")
                    
                    total_campus = len(optimized_data)
                    context_extra += (
                        f"\n\n[SYST√àME: DONN√âES CAMPUS LIVE - {total_campus} CAMPUS TROUV√âS]\n"
                        f"‚ö†Ô∏è IMPORTANT : Il y a EXACTEMENT {total_campus} campus dans cette liste. "
                        f"Tu DOIS tous les mentionner si on te demande de lister les campus.\n"
                        f"M√™me si les formations sont identiques (ex: Madrid/Barcelone), CITE CHAQUE VILLE S√âPAR√âMENT.\n\n"
                        f"Liste compl√®te des campus ({total_campus}) :\n"
                        f"{campus_text}\n\n"
                        f"Si on te demande combien il y a de campus, r√©ponds : {total_campus}. "
                        f"Si on te demande de les lister, cite TOUS les {total_campus} campus de la liste ci-dessus."
                    )
                    backend_source += " + Scraper Campus"
                else:
                    print("   ‚ö†Ô∏è √âchec du scraping campus")
            else:
                print("   ‚Üí Pas de scraping campus demand√©")

            # Tool 1.7: Degrees / Programmes Scraper (Live)
            print("üîç [2.7/6] V√©rification demande scraping dipl√¥mes/programmes...")
            if tool_decisions["degrees"].call:
                print("   ‚ö° SCRAPER DEGREES ACTIV√â - D√©marrage...")
                if tool_decisions["degrees"].reasons:
                    print(f"   ‚Ü≥ raisons: {', '.join(tool_decisions['degrees'].reasons[:6])}")
                logger.info("Tool Activation: Scraper Degrees")
                degrees_data = await tool_tasks["degrees"]

                if degrees_data and isinstance(degrees_data, dict):
                    items = degrees_data.get("data", [])
                    print(f"   ‚úì Scraping degrees termin√© : {len(items)} programmes")

                    # Build a compact, source-first block (LLM must cite URLs).
                    sources: list[str] = []
                    blocks: list[str] = []
                    for prog in items:
                        if not isinstance(prog, dict):
                            continue
                        nom = prog.get("nom")
                        niveau = prog.get("niveau")
                        cat = prog.get("categorie")
                        pages = prog.get("pages", []) if isinstance(prog.get("pages"), list) else []

                        header_parts = [p for p in [nom, cat, niveau] if p]
                        header = " - ".join(header_parts) if header_parts else "Programme"

                        # Keep only a few page snippets in the prompt (avoid token explosion),
                        # but keep ALL URLs in Sources.
                        page_lines: list[str] = []
                        for p in pages:
                            if not isinstance(p, dict):
                                continue
                            url = p.get("url")
                            if isinstance(url, str):
                                sources.append(url)
                            title = p.get("h1") or p.get("title")
                            desc = p.get("description")
                            snippet = p.get("snippet")
                            duration_hints = p.get("duration_hints") if isinstance(p.get("duration_hints"), list) else []
                            line = f"- {title}" if title else "- Page"
                            if snippet and isinstance(snippet, str):
                                line += f": {snippet[:220]}{'‚Ä¶' if len(snippet) > 220 else ''}"
                            if duration_hints:
                                # Show at most 2 duration hints to keep it compact.
                                dh = ", ".join([str(x) for x in duration_hints[:2]])
                                line += f" (Dur√©e rep√©r√©e: {dh})"
                            if url:
                                line += f" (Source: {url})"
                            # Show max 2 lines per programme to keep prompt small
                            page_lines.append(line)
                            if len(page_lines) >= 2:
                                break

                        blocks.append(header + "\n" + "\n".join(page_lines))

                    # Deduplicate sources while preserving order
                    seen = set()
                    uniq_sources: list[str] = []
                    for u in sources:
                        if u in seen:
                            continue
                        seen.add(u)
                        uniq_sources.append(u)

                    degrees_text = "\n\n".join(blocks) if blocks else "Aucune donn√©e exploitable."
                    context_extra += (
                        "\n\n[SYST√àME: DONN√âES DIPL√îMES/PROGRAMMES LIVE]\n"
                        "Voici les informations OFFICIELLES scrap√©es (avec sources) :\n"
                        f"{degrees_text}\n\n"
                        "SOURCES (√† afficher dans la r√©ponse) :\n"
                        + "\n".join(f"- {u}" for u in uniq_sources[:25])
                        + ("\n- ... (autres sources disponibles)" if len(uniq_sources) > 25 else "")
                        + "\n\n"
                        "R√àGLES STRICTES :\n"
                        "- Commence ta r√©ponse par **1 phrase de reformulation** (ex: \"Si je reformule, tu veux la liste des sp√©cialisations Epitech...\").\n"
                        "- N'INVENTE PAS de sp√©cialit√©s/secteurs (ex: sant√©, √©nergie, biotech...) si ce n'est pas dans la liste ci-dessus.\n"
                        "- N'INVENTE PAS de dur√©es (1 an / 2 ans / etc.) : ne donne une dur√©e que si elle appara√Æt dans les lignes \"Dur√©e rep√©r√©e\" ci-dessus, et cite la page correspondante.\n"
                        "- Si l'utilisateur demande le **MBA**, et que des pages MBA sont dans les SOURCES, tu DOIS confirmer que le MBA existe et r√©pondre UNIQUEMENT avec ces pages (ne le nie jamais).\n"
                        "- Si l'utilisateur demande le d√©tail des sp√©cialisations, dis que tu peux expliquer les grandes familles (PGE/MSc/Coding Academy) mais que tu n'as pas le catalogue complet.\n"
                        "- Quand tu donnes un d√©tail (programme/specialisation), ajoute la/les URL(s) correspondantes en 'Sources:' √† la fin.\n"
                        "Utilise ces donn√©es comme source prioritaire si l'utilisateur demande les dipl√¥mes, programmes ou cursus."
                    )
                    if needs_track_clarification:
                        context_extra += (
                            "\n\n[INSTRUCTION]\n"
                            "L'utilisateur n'a pas pr√©cis√© s'il parle du Bachelor ou des MSc/MBA. "
                            "Apr√®s avoir donn√© une liste courte et fiable (avec sources), pose UNE question: "
                            "\"Tu vises le Bachelor ou les MSc/MBA, et tu es √† quel niveau (Bac+2/Bac+3/reconversion)?\""
                        )
                    backend_source += " + Scraper Degrees"
                else:
                    print("   ‚ö†Ô∏è √âchec du scraping degrees")
            else:
                print("   ‚Üí Pas de scraping dipl√¥mes/programmes demand√©")

            # Tool 2: Campus Finder
            print("üîç [3/6] D√©tection de localisation...")
            location_context = await self._process_location_detection(
                request.message, msg_lower
            )
            if location_context:
                print("   ‚úì Localisation d√©tect√©e et trait√©e")
                context_extra += location_context
            else:
                print("   ‚Üí Aucune localisation d√©tect√©e")

            # Detect study level
            print("üîç [4/6] D√©tection du niveau d'√©tudes...")
            detected_level = self._detect_study_level(request.message, request.history)
            if detected_level:
                print(f"   ‚úì Niveau d√©tect√©: {detected_level}")
            else:
                print("   ‚Üí Niveau non d√©tect√©")
            level_context = self._build_level_context(detected_level)

            # Build system prompt
            print("üîç [5/6] Construction du prompt syst√®me...")
            system_content = self._build_system_prompt(level_context)
            print("   ‚úì Prompt syst√®me construit")

            # Build messages for Ollama
            print("üîç [6/6] Pr√©paration des messages pour Ollama...")
            messages = self._build_messages(
                system_content,
                request.message,
                request.history,
                context_extra,
                user_lang
            )
            print(f"   ‚úì {len(messages)} messages pr√©par√©s")

            # Call Ollama with timeout and resource limits
            print(f"\nü§ñ APPEL √Ä OLLAMA...")
            print(f"   Mod√®le: {settings.ollama_model}")
            print(f"   Timeout: {settings.ollama_timeout}s")
            try:
                import asyncio
                import time
                start_time = time.time()
                
                # Wrap synchronous ollama.chat in a thread to prevent blocking
                def call_ollama():
                    return ollama.chat(
                        model=settings.ollama_model,
                        messages=messages,
                        options={
                            "temperature": settings.ollama_temperature,
                            "num_ctx": 2048,  # Limite le contexte pour √©conomiser la m√©moire
                            "num_predict": 512,  # Limite la longueur de la r√©ponse
                        }
                    )
                
                # Use async with timeout to prevent system freeze
                loop = asyncio.get_event_loop()
                response = await asyncio.wait_for(
                    loop.run_in_executor(None, call_ollama),
                    timeout=settings.ollama_timeout
                )
                elapsed_time = time.time() - start_time
                response_length = len(response['message']['content'])
                print(f"   ‚úì R√©ponse re√ßue en {elapsed_time:.2f}s ({response_length} caract√®res)")
            except asyncio.TimeoutError:
                logger.error(f"Ollama request timeout after {settings.ollama_timeout}s")
                raise OllamaError(
                    f"La requ√™te a pris trop de temps (>{settings.ollama_timeout}s). "
                    "Essayez un mod√®le plus l√©ger (llama3.2:1b) ou r√©duisez la longueur du message."
                )
            except Exception as ollama_error:
                error_msg = str(ollama_error)
                logger.error(f"Ollama connection error: {error_msg}")
                
                # Check if it's a connection error
                if "connection" in error_msg.lower() or "connect" in error_msg.lower():
                    raise OllamaError(
                        "Ollama n'est pas en cours d'ex√©cution. "
                        "Veuillez d√©marrer Ollama avec la commande : ollama serve"
                    )
                else:
                    raise OllamaError(f"Erreur Ollama : {error_msg}")

            print("=" * 60)
            print("‚úÖ REQU√äTE TRAIT√âE AVEC SUCC√àS")
            print(f"   Source: {backend_source}")
            print("=" * 60 + "\n")
            
            return {
                "response": response['message']['content'],
                "backend_source": backend_source
            }

        except OllamaError:
            # Re-raise Ollama errors as-is
            raise
        except Exception as e:
            logger.error(f"Unexpected error in chat service: {e}")
            raise OllamaError(f"Failed to process chat: {str(e)}")

    def _format_campus_to_text(self, data: List[Dict]) -> str:
        """Format optimized campus data into a compact text list."""
        lines = []
        for idx, c in enumerate(data, 1):
            ville = c['ville'].upper()
            pays = c['pays']
            forms = ", ".join(c['formations'][:3]) if c['formations'] else "Toutes formations"  # Limiter √† 3 formations max
            if len(c['formations']) > 3:
                forms += f" (+{len(c['formations']) - 3} autres)"
            lines.append(f"{idx}. {ville} ({pays}) : {forms}")
        return "\n".join(lines)

    def _optimize_campus_data(self, data: Any) -> List[Dict]:
        """Optimize and filter campus data to reduce token usage."""
        optimized = []
        # MCP Server returns {"data": [...], "meta": {...}}
        if isinstance(data, dict) and isinstance(data.get("data"), list):
            data = data.get("data")
        if not isinstance(data, list):
            return []

        for campus in data:
            if not isinstance(campus, dict): continue
            
            # Filter out error messages if any
            if "error" in campus: continue

            # Simple filtered object
            opt_campus = {
                "ville": campus.get("ville"),
                "pays": campus.get("pays"),
                "formations": []
            }
            
            # Filter formations
            raw_formations = campus.get("formations_disponibles", [])
            seen_names = set()
            
            for fmt in raw_formations:
                if not isinstance(fmt, dict): continue
                name = fmt.get("nom", "")
                name_lower = name.lower()
                
                # Filter out irrelevant marketing/contact titles (Noise reduction)
                if any(bad in name_lower for bad in [
                    "o√π √©tudier", "plan d‚Äôacc√®s", "choisir l‚Äô√©cole", "contact", 
                    "informations", "t√©l√©charger", "brochure", "plus qu‚Äôune √©cole",
                    "nos formations", "nos campus"
                ]):
                    continue
                    
                # Keep relevant academic programs
                if any(k in name_lower for k in ["programme", "bachelor", "master", "msc", "coding", "w@c", "web@cad√©mie", "bootcamp", "pge", "grande ecole", "grande √©cole"]):
                    # Deduplicate
                    if name in seen_names: continue
                    seen_names.add(name)
                    opt_campus["formations"].append(name)
            
            # Add to list if valid location (on exclut les faux "campus" g√©n√©riques type 'Apres Bac')
            ville_val = opt_campus["ville"]
            if ville_val and ville_val.lower() not in {"apres bac", "apr√®s bac"}:
                optimized.append(opt_campus)
                 
        return optimized

    # NOTE: Tool routing is handled by app.utils.tool_router.ToolRouter.

    async def _process_location_detection(
        self, message: str, msg_lower: str
    ) -> Optional[str]:
        """
        Process location detection and return context string.
        
        Returns:
            Context string to add to prompt, or None
        """
        # Check if this is a general Epitech question (not location-related)
        is_general_question = any(
            kw in msg_lower for kw in self.NON_LOCATION_KEYWORDS
        )

        if is_general_question:
            return None

        # Extract location query
        location_query = self._extract_location_query(message, msg_lower)

        if not location_query:
            return None

        logger.info(f"Location query detected: {location_query}")

        # Check for direct city match
        direct_city_match = self._find_direct_city_match(location_query)

        if direct_city_match:
            logger.info(f"Direct city match: {direct_city_match}")
            city = direct_city_match
            data = CAMPUSES[city]
            return (
                f"\n\n[INFO SYST√àME: CAMPUS PR√âSENT !]\n"
                f"Epitech est √† {city.upper()} !\n"
                f"Adresse : {data['addr']}.\n"
                f"Contact : {data.get('email', 'N/A')} | {data.get('phone', 'N/A')}\n"
            )

        # Use geocoding API
        logger.info(f"Geocoding API: {location_query}")
        geo_result = await self.geocoding_service.get_nearest_campus(location_query)

        if not geo_result:
            return None

        nearest_overall, nearest_in_country, user_detected_info = geo_result

        city = nearest_overall['city']
        data = nearest_overall['data']
        dist_km = nearest_overall['dist']

        # Recommendation logic (prioritize country if relevant)
        rec_city = city
        rec_data = data
        rec_dist = dist_km
        is_national_priority = False

        if nearest_in_country and nearest_in_country['city'] != rec_city:
            nat_dist = nearest_in_country['dist']
            if nat_dist < (rec_dist + 200):
                rec_city = nearest_in_country['city']
                rec_data = nearest_in_country['data']
                rec_dist = nat_dist
                is_national_priority = True

        is_same_city = (
            location_query.lower() in rec_city.lower()
            or rec_city.lower() in location_query.lower()
        )

        if is_same_city or rec_dist < 10:
            return (
                f"\n\n[INFO SYST√àME: CAMPUS PR√âSENT !]\n"
                f"Epitech est √† {rec_city.upper()} !\n"
                f"Adresse : {rec_data['addr']}.\n"
                f"Contact : {rec_data.get('email', 'N/A')} | {rec_data.get('phone', 'N/A')}\n"
            )
        else:
            priority_msg = (
                "PR√âF√âRENCE NATIONALE" if is_national_priority else "PROXIMIT√â"
            )
            context = (
                f"\n\n[INFO SYST√àME: LOCALISATION]\n"
                f"Localisation d√©tect√©e : '{location_query}' ({user_detected_info}).\n"
                f"Campus recommand√© ({priority_msg}) : {rec_city.upper()} ({rec_dist} km).\n"
                f"Adresse : {rec_data['addr']}.\n"
                f"Contact : {rec_data.get('email', 'N/A')} | {rec_data.get('phone', 'N/A')}\n"
            )

            if not is_same_city and rec_dist > 5:
                context += (
                    f"\n‚ö†Ô∏è GARDE-FOU : Il n'y a PAS de campus √† {location_query}. "
                    f"Le plus proche est {rec_city} ({rec_dist}km). "
                    f"N'invente JAMAIS d'adresse pour {location_query}.\n"
                )

            return context

    def _extract_location_query(self, message: str, msg_lower: str) -> Optional[str]:
        """Extract location query from message using regex patterns."""
        # 1. Zip code (5 digits)
        zip_match = re.search(r'\b\d{5}\b', message)
        if zip_match:
            return zip_match.group(0)

        # 2. City with location verb
        city_match = re.search(
            r'(?i)\b(?:habite|vis|viens|suis)\s+(?:√†|a|de|d\')\s*([a-zA-Z\u00C0-\u00FF]{3,})\b',
            message
        )
        if city_match:
            candidate = city_match.group(1).strip().lower()
            if candidate not in self.INVALID_LOCATION_WORDS:
                return city_match.group(1).strip()

        # 3. "campus [ville]" or "Epitech [ville]"
        campus_city_match = re.search(
            r'(?i)(?:campus|epitech)\s+([a-zA-Z\u00C0-\u00FF\-]+)',
            message
        )
        if campus_city_match:
            candidate = campus_city_match.group(1).strip()
            if (
                candidate.lower() in [c.lower() for c in CAMPUSES.keys()]
                or candidate.lower() in CITY_ALIASES
            ):
                return candidate

        # 4. Known city mentioned directly
        for known_city in CAMPUSES.keys():
            if re.search(rf'\b{re.escape(known_city.lower())}\b', msg_lower):
                return known_city

        # 5. Check aliases
        for alias, target_city in CITY_ALIASES.items():
            if re.search(rf'\b{re.escape(alias)}\b', msg_lower):
                return target_city

        return None

    def _find_direct_city_match(self, location_query: str) -> Optional[str]:
        """Find direct city match without geocoding."""
        loc_normalized = location_query.lower()

        for known_city in CAMPUSES.keys():
            if known_city.lower() == loc_normalized:
                return known_city

        if loc_normalized in CITY_ALIASES:
            return CITY_ALIASES[loc_normalized]

        return None

    def _detect_study_level(
        self, message: str, history: List[MessageHistory]
    ) -> Optional[str]:
        """Detect study level from message and history."""
        full_user_context = message.lower()
        if history:
            for turn in history:
                if turn.sender == "user":
                    full_user_context += " " + turn.text.lower()

        # Prefer explicit "bac+N" patterns before keyword scanning (avoids matching "bac " in "bac +2").
        m = re.search(r"\bbac\s*\+\s*(\d)\b", full_user_context)
        if m:
            n = m.group(1)
            if n in {"2", "3", "4", "5"}:
                return f"bac+{n}"
            if n == "0":
                return "bac"

        for level, keywords in self.LEVEL_KEYWORDS.items():
            for kw in keywords:
                if kw in full_user_context:
                    logger.info(f"Study level detected: {level} (keyword: '{kw}')")
                    return level

        return None

    def _build_level_context(self, detected_level: Optional[str]) -> str:
        """Build context string based on detected study level."""
        if not detected_level:
            return (
                "\n\n[INFO SYST√àME: NIVEAU D'√âTUDES INCONNU]\n"
                "‚ö†Ô∏è Tu ne sais PAS encore quel niveau scolaire a l'utilisateur.\n"
                "1. NE PROPOSE AUCUN CURSUS SP√âCIFIQUE (ni PGE, ni MSc...).\n"
                "2. DEMANDE-LUI d'abord : 'Pour te conseiller au mieux, quel est ton niveau d'√©tudes actuel (Lyc√©e, Bac+2, Reconversion...) ?'\n"
                "3. N'invente pas un profil √† l'utilisateur.\n"
            )

        if detected_level in ["bac", "lycee"]:
            return (
                "\n\n[INFO SYST√àME: NIVEAU D√âTECT√â = BAC/LYC√âE]\n"
                "L'utilisateur est niveau Bac/Lyc√©e. Propose UNIQUEMENT le 'Programme Grande √âcole' (5 ans).\n"
            )
        elif detected_level in ["bac+2", "bac+3", "bac+4", "bac+5"]:
            return (
                f"\n\n[INFO SYST√àME: NIVEAU D√âTECT√â = {detected_level.upper()}]\n"
                "‚ö†Ô∏è ATTENTION : L'utilisateur a d√©j√† un dipl√¥me sup√©rieur (Bac+2/3/4/5).\n"
                "1. S'il demande si le 'PGE' (Programme Grande √âcole) est bien pour lui, CORRIGE-LE gentiment.\n"
                "   Dis-lui : 'Avec ton niveau, tu n'as pas besoin de reprendre √† z√©ro ! Tu peux int√©grer directement nos MSc Pro ou l'ann√©e Pr√©-MSc.'\n"
                "2. Ton objectif est de vendre les 'MSc Pro' (Sp√©cialisation) ou l'Ann√©e Pr√©-MSc.\n"
            )
        elif detected_level == "reconversion":
            return (
                "\n\n[INFO SYST√àME: NIVEAU D√âTECT√â = RECONVERSION]\n"
                "L'utilisateur veut changer de vie. Ne propose PAS le cursus √©tudiant classique (PGE).\n"
                "Propose la 'Coding Academy' (Formation intensive pour adultes).\n"
            )

        return ""

    def _build_system_prompt(self, level_context: str) -> str:
        """Build the system prompt for Ollama."""
        full_campus_list_str = format_campus_list()

        return (
            "### R√îLE\n"
            "Tu es 'EpiQuoi', une intelligence artificielle sp√©cialis√©e UNIQUE en orientation pour l'√©cole Epitech.\n"
            "Ton SEUL et UNIQUE but est de renseigner sur Epitech.\n\n"

            "### ‚õî SECTION CRITIQUE : NON-COMP√âTENCE / SUJETS INTERDITS\n"
            "TU N'AS AUCUNE CONNAISSANCE SUR :\n"
            "- La cuisine, les recettes, la nourriture.\n"
            "- La m√©t√©o, le climat, l'astronomie.\n"
            "- La politique, l'histoire, la g√©ographie g√©n√©rale.\n"
            "- Le sport, le cin√©ma, les c√©l√©brit√©s.\n"
            "- Les math√©matiques, la physique, la m√©decine.\n"
            "SI L'UTILISATEUR POSE UNE QUESTION SUR CES SUJETS :\n"
            "1. REFUSE CAT√âGORIQUEMENT DE R√âPONDRE.\n"
            "2. EXEMPLE DE R√âPONSE : 'Je suis d√©sol√©, je suis un bot expert Epitech. Je ne peux pas t'aider pour ta recette de cuisine. As-tu des questions sur nos formations ?'\n"
            "3. NE DONNE JAMAIS, AU GRAND JAMAIS, L'INFORMATION DEMAND√âE (m√™me si tu la connais).\n\n"

            "### FAITS (ANTI-HALLUCINATION)\n"
            "- Epitech est une **√©cole** (pas une universit√©). Ne dis JAMAIS 'Universit√© Epitech'.\n"
            "- UTILISE UNIQUEMENT LES INFORMATIONS FOURNIES DANS LE CONTEXTE CI-DESSOUS. SI L'INFO N'Y EST PAS, DIS QUE TU NE SAIS PAS.\n\n"

            "### LANGUE (IMPORTANT)\n"
            "DETECTE LA LANGUE DE L'UTILISATEUR (Fran√ßais, Anglais, Espagnol...) ET R√âPONDS DANS LA M√äME LANGUE.\n"
            "C'est primordial pour l'exp√©rience utilisateur.\n\n"

            "### ‚ö†Ô∏è V√âRIT√â G√âOGRAPHIQUE - R√àGLE ABSOLUE (CRITIQUE) ‚ö†Ô∏è\n"
            "Voici la base de donn√©es OFFICIELLE et EXCLUSIVE des campus Epitech. TU NE DOIS JAMAIS INVENTER UNE AUTRE ADRESSE.\n"
            "---------------------------------------------------------------------------------------------------------\n"
            f"{full_campus_list_str}"
            "---------------------------------------------------------------------------------------------------------\n"
            "R√àGLES IMP√âRATIVES :\n"
            "1. Si on te demande l'adresse de Paris, Lille, Bordeaux... COPIE-COLLE L'ADRESSE DE LA LISTE CI-DESSUS.\n"
            "2. Si l'utilisateur demande une ville NON list√©e (ex: Metz, Brest...) : TU DOIS DIRE qu'il n'y a pas de campus.\n"
            "3. N'INVENTE JAMAIS RIEN. Utilise uniquement la liste ci-dessus.\n\n"

            "### PROTOCOLE DE PROFILAGE (CRITIQUE)\n"
            "‚ö†Ô∏è AVANT DE DEMANDER LE NIVEAU D'√âTUDES, V√âRIFIE SI L'UTILISATEUR L'A D√âJ√Ä MENTIONN√â !\n"
            "Mots-cl√©s : 'bac', 'stmg', 'sti2d', 'licence', 'bts', 'dut', 'master', 'reconversion', 'lyc√©e', 'terminale'...\n"
            "SI D√âTECT√â ‚Üí Passe DIRECTEMENT aux recommandations !\n\n"

            "RECOMMANDATIONS PAR NIVEAU :\n"
            "   - Lyc√©e/Bac (STMG, STI2D, Bac Pro...) ‚Üí 'Programme Grande √âcole' (5 ans post-bac).\n"
            "   - Bac+2/3 (BTS, DUT, Licence) ‚Üí 'MSc Pro' (IA, Data, Cyber) ou 'Ann√©e Pr√©-MSc'.\n"
            "   - Reconversion ‚Üí 'Coding Academy'.\n"
            "   - SI LE NIVEAU EST INCONNU : DEMANDE-LE AVANT DE PROPOSER QUOI QUE CE SOIT.\n\n"
            
            "### PHASE DE CONVERSION (IMPORTANT)\n"
            "SIGNAUX D'INT√âR√äT √† d√©tecter : 'int√©ressant', 'cool', 'sympa', '√ßa a l'air', 'je veux', 'inscription', 'oui'...\n"
            "SI SIGNAL D√âTECT√â :\n"
            "   1. Confirme son int√©r√™t (ex: 'Content que √ßa te plaise !').\n"
            "   2. Propose NATURELLEMENT de passer √† l'√©tape suivante (contact, visite, candidature).\n"
            "   3. Donne les coordonn√©es du campus le plus pertinent (Localisation utilisateur OU Campus mentionn√©).\n"
            "      SI AUCUNE VILLE D√âTECT√âE : Donne les coordonn√©es g√©n√©riques ou demande sa ville.\n"
            "   4. RESTE NATUREL : pas de forcing commercial.\n\n"

            "### INTERDICTIONS STRICTES\n"
            "- NE PAS METTRE DE NOTES DU GENRE '(Note: ...)' ou '(Remember: ...)' dans ta r√©ponse. Jamais.\n"
            "- HORS-SUJET : Blague tech + STOP (Sauf si le sujet est explicitement interdit, alors refus strict).\n"
            "- Cursus valides uniquement : 'Programme Grande √âcole', 'MSc Pro', 'Coding Academy'.\n\n"

            "### TRAME\n"
            "- Direct, tutoiement, enthousiaste.\n"
            "- Ne r√©p√®te pas ce que l'utilisateur a d√©j√† dit.\n"
            "- TOUJOURS r√©pondre dans la langue de l'utilisateur.\n"
            f"{level_context}"
        )

    def _build_messages(
        self,
        system_content: str,
        user_message: str,
        history: List[MessageHistory],
        context_extra: str,
        user_lang: str
    ) -> List[Dict[str, str]]:
        """Build messages list for Ollama."""
        messages = [{'role': 'system', 'content': system_content}]

        # Add history
        if history:
            for turn in history[-settings.max_history_messages:]:
                role = "assistant" if turn.sender == "bot" else "user"
                if not turn.isError:
                    messages.append({'role': role, 'content': turn.text})

        # Build final user message with context
        final_user_content = user_message
        if context_extra:
            final_user_content += f"\n\n(Information syst√®me : {context_extra})"

        # Add language instruction
        if user_lang != 'fr':
            final_user_content += (
                f"\n\n[CRITICAL: THE USER SPEAKS {user_lang.upper()}. "
                f"YOU MUST ANSWER IN {user_lang.upper()}. DO NOT SPEAK FRENCH.]"
            )
        else:
            final_user_content += (
                "\n\n[INSTRUCTION SYST√àME ULTIME : "
                "R√âPONDS DANS LA M√äME LANGUE QUE LE MESSAGE DE L'UTILISATEUR]"
            )

        messages.append({'role': 'user', 'content': final_user_content})

        return messages
